% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mfp2.R
\name{mfp2}
\alias{mfp2}
\alias{mfp2.default}
\alias{mfp2.formula}
\title{Multivariable Fractional Polynomial Models with Extensions}
\usage{
mfp2(x, ...)

\method{mfp2}{default}(
  x,
  y,
  weights = NULL,
  offset = NULL,
  cycles = 5,
  scale = NULL,
  shift = NULL,
  df = 4,
  center = TRUE,
  subset = NULL,
  family = c("gaussian", "poisson", "binomial", "Gamma", "cox"),
  criterion = c("pvalue", "aic", "bic"),
  select = 0.05,
  alpha = 0.05,
  keep = NULL,
  xorder = c("ascending", "descending", "original"),
  powers = NULL,
  ties = c("breslow", "efron", "exact"),
  strata = NULL,
  nocenter = NULL,
  acdx = NULL,
  ftest = FALSE,
  control = NULL,
  zero = NULL,
  catzero = NULL,
  spike = NULL,
  min_prop = 0.05,
  max_prop = 0.95,
  verbose = TRUE,
  ...
)

\method{mfp2}{formula}(
  formula,
  data,
  weights = NULL,
  offset = NULL,
  cycles = 5,
  scale = NULL,
  shift = NULL,
  df = 4,
  center = TRUE,
  subset = NULL,
  family = c("gaussian", "poisson", "binomial", "Gamma", "cox"),
  criterion = c("pvalue", "aic", "bic"),
  select = 0.05,
  alpha = 0.05,
  keep = NULL,
  xorder = c("ascending", "descending", "original"),
  powers = NULL,
  ties = c("breslow", "efron", "exact"),
  strata = NULL,
  nocenter = NULL,
  ftest = FALSE,
  control = NULL,
  min_prop = 0.05,
  max_prop = 0.95,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{x}{for \code{mfp2.default}: \code{x} is an input matrix of dimensions
nobs x nvars. Each row is an observation vector.}

\item{...}{not used.}

\item{y}{for \code{mfp2.default}: \code{y} is a vector for the response variable.
For \code{family = "binomial"} it should be  a vector with two levels (see
\code{\link[stats:glm]{stats::glm()}}). For \code{family = "cox"} it must be a \code{\link[survival:Surv]{survival::Surv()}} object
containing 2 columns.}

\item{weights}{a vector of observation weights of length nobs.
Default is \code{NULL} which assigns a weight of 1 to each observation.}

\item{offset}{a vector of length nobs that is included in the linear
predictor. Useful for the poisson family (e.g. log of exposure time).
Default is \code{NULL} which assigns an offset  of 0 to each observation.
If supplied, then values must also be supplied to the \code{predict()} function.}

\item{cycles}{an integer, specifying the maximum number of iteration cycles.
Default is 5.}

\item{scale}{a numeric vector of length \code{nvars} or single numeric specifying
scaling factors. If a single numeric, then the value will be replicated as
necessary. The formula interface \code{mfp2.formula} only supports single numeric
input to set a default value, individual values can be set using \code{fp} terms
in the \code{formula} input.
Default is \code{NULL} which lets the program estimate the scaling factors
(see Details section). If scaling is not required set \code{scale = 1} to disable
it. The final regression coefficients are expressed in the original scale of
the data.}

\item{shift}{a numeric vector of length \code{nvars} or a single numeric specifying
shift terms. If a single numeric, then the value will be replicated as
necessary. The formula interface \code{mfp2.formula} only supports single numeric
input to set a default value, individual values can be set using \code{fp} terms
in the \code{formula} input.
Default is \code{NULL} which lets the program estimate the shifts
(see Details section). If shifting is not required, set \code{shift = 0} to
disable it.}

\item{df}{a numeric vector of length nvars or a single numeric that sets the
(default) degrees of freedom (df) for each predictor. If a single numeric,
then the value will be replicated as necessary. The formula interface
\code{mfp2.formula} only supports single numeric input to set a default value,
individual values can be set using \code{fp} terms in the \code{formula} input.
The df (not counting the intercept) are twice the degree of a fractional
polynomial (FP). For example, an FP2 has 4 df, while FPm has 2*m df.
The program overrides default df based on the number of distinct (unique)
values for a variable as follows:
2-3 distinct values are assigned \code{df = 1} (linear), 4-5 distinct values are
assigned \code{df = min(2, default)} and >= 6 distinct values are assigned
\code{df = default}.}

\item{center}{a logical determining whether variables are centered before
final model fitting. The default \code{TRUE} implies mean centering, except for
binary covariates, where the covariate is centered using the lower of the two
distinct values of the covariate. See Details section below.}

\item{subset}{an optional vector specifying a subset of observations
to be used in the fitting process. Default is \code{NULL} and all observations are
used. See Details below.}

\item{family}{a character string representing a \code{glm()} family object as well
as Cox models. For more information, see details section below.}

\item{criterion}{a character string specifying the criterion used to select
variables and FP models of different degrees.
Default is to use p-values in which case the user can specify
the nominal significance level (or use default level of 0.05) for variable and
functional form selection (see \code{select} and \code{alpha} parameters below).
If the user specifies the BIC (\code{bic}) or AIC (\code{aic}) criteria the program
ignores the nominal significance levels and selects variables and functional
forms using the chosen information criterion.}

\item{select}{a numeric vector of length nvars or a single numeric that
sets the nominal significance levels for variable selection on each predictor
by backward elimination. If a single numeric, then the value will be replicated
as necessary. The formula interface \code{mfp2.formula} only supports single numeric
input to set a default value, individual values can be set using \code{fp} terms
in the \code{formula} input. The default nominal significance level is 0.05
for all variables. Setting the nominal significance level to be 1 for
certain variables forces them into the model, leaving all other variables
to be selected.}

\item{alpha}{a numeric vector of length nvars or a single numeric that
sets the significance levels for testing between FP models of
different degrees. If a single numeric, then the value will be replicated
as necessary. The formula interface \code{mfp2.formula} only supports single numeric
input to set a default value, individual values can be set using \code{fp} terms
in the \code{formula} input. The default nominal significance level is 0.05 for all
variables.}

\item{keep}{a character vector with names of variables to be kept
in the model. In case that \code{criterion = "pvalue"}, this is equivalent to
setting the selection level for the variables in \code{keep} to 1.
However, this option also keeps the specified variables in the model when
using the BIC or AIC criteria.}

\item{xorder}{a string determining the order of entry of the covariates
into the model-selection algorithm. The default is \code{ascending}, which enters
them by ascending p-values, or decreasing order of significance in a
multiple regression (i.e. most significant first).
\code{descending} places them in reverse significance order, whereas
\code{original} respects the original order in \code{x}.}

\item{powers}{a named list of numeric values specifying the set of candidate
FP powers for each covariate. The default is \code{NULL}, in which case every
covariate is assigned \code{powers = c(-2, -1, -0.5, 0, 0.5, 1, 2, 3)}, where
\code{0} denotes the natural logarithm. Powers are sorted before further
processing. If some variables are not explicitly assigned powers, the default
set is used. In the formula interface, powers can be specified either through
the \code{powers} argument or within the \code{fp()} function. If both are provided for
the same variable, the specification inside \code{fp()} takes precedence. Each
variable must be assigned at least two candidate powers for model selection.
To restrict a variable to a single transformation, pre-transform the variable
and fit it with \code{df = 1}.}

\item{ties}{a character string specifying the method for tie handling in
Cox regression. If there are no tied death times all the methods are
equivalent. Default is the Breslow method. This argument is used for Cox
models only and has no effect on other model families.
See \code{\link[survival:coxph]{survival::coxph()}} for details.}

\item{strata}{a numeric vector or matrix of variables that define strata
to be used for stratification in a Cox model. A new factor, whose levels are
all possible combinations of the variables supplied will be created.
Default is \code{NULL} and a Cox model without stratification would be fitted.
See \code{\link[survival:coxph]{survival::coxph()}} for details.}

\item{nocenter}{a numeric vector with a list of values for fitting Cox
models. See \code{\link[survival:coxph]{survival::coxph()}} for details.}

\item{acdx}{a character vector giving the names of continuous variables to
undergo the approximate cumulative distribution (ACD) transformation. Using
this also triggers the function-selection procedure for ACD to determine the
best-fitting FP1(p1, p2) model (see Details). This argument is not available
in the formula interface (\code{mfp2.formula}), where the user should instead use
\code{fp()}. Within \code{fp()} terms, the ACD transformation is specified via the
logical argument \code{acdx} rather than by listing variable names. The variable
representing the ACD transformation of \code{x} is named \code{A_x}.}

\item{ftest}{a logical indicating whether \code{mfp2} should use critical values
from the F-distribution instead of the Chi-Square distribution for small-sample
normal error models. This affects variable selection, functional form selection,
and spike-at-zero testing when evaluating fractional polynomial terms. Default
is \code{FALSE}, in which case the Chi-Square distribution is used. This argument
applies only to Gaussian models.}

\item{control}{a list of parameters controlling the fitting process, as
returned by \code{\link[stats:glm.control]{stats::glm.control()}} or \code{\link[survival:coxph.control]{survival::coxph.control()}}. Default
is \code{NULL}, in which case \code{mfp2} uses the default settings for the specified
model family.}

\item{zero}{A character vector specifying the names of continuous variables
for which nonpositive values should be treated as zero. This enables fitting a
fractional polynomial (FP) model using only the positive values of the
covariate, while setting nonpositive values to zero during transformation.
In \code{fp()} terms, \code{zero} is a logical value indicating whether the adjustment
should be applied to the variable. See the \strong{Details} section.}

\item{catzero}{A character vector specifying the names of continuous variables
for which nonpositive values should be treated as zero, similar to \code{zero}. In
addition, \code{mfp2} automatically creates a binary indicator variable and
includes it in the model alongside the transformed variable.
In \code{fp()} terms, \code{catzero} is a logical value indicating whether the adjustment
and indicator should be applied. See the \strong{Details} section.}

\item{spike}{A character vector specifying the names of continuous variables
to be assessed for a spike at zero. Supplying this triggers the spike-at-zero
(SAZ) algorithm (see Details). This argument is not available in the formula
interface (\code{mfp2.formula}), where spike is specified as a logical value within
\code{fp()} terms for each variable.}

\item{min_prop}{A numeric value between 0 and 1; the minimum proportion of
zeros for which the spike-at-zero (SAZ) modeling is applied. Defaults to 0.05.}

\item{max_prop}{A numeric value between 0 and 1; the maximum proportion of
zeros for which SAZ modeling is applied. Defaults to 0.95.}

\item{verbose}{a logical; run in verbose mode.}

\item{formula}{for \code{mfp2.formula}: an object of class \code{formula}: a symbolic
description of the model to be fitted. Special \code{fp} terms can be used to
define fp-transformations. The details of model specification are given
under ‘Details’.}

\item{data}{for \code{mfp2.formula}: a \code{data.frame} which contains all variables
specified in \code{formula}.}
}
\value{
\code{mfp2()} returns an object of class inheriting from \code{glm} or \code{copxh},
depending on the \code{family} parameter.

The function \code{summary()} (i.e. \code{\link[=summary.mfp2]{summary.mfp2()}}) can be used to obtain or
print a summary of the results.
The generic accessor function \code{coef()} can be used to extract the vector of
coefficients from the fitted model object.
The generic \code{predict()} can be used to obtain predictions from the fitted
model object.

An object of class \code{mfp2} is a list containing all entries as for \code{glm}
or \code{coxph}, and in addition the following entries:
\itemize{
\item convergence_mfp: logical value indicating convergence of mfp algorithm.
\item fp_terms: a data.frame with information on fractional polynomial
terms.
\item transformations: a data.frame with information on shifting, scaling
and centering for all variables.
\item fp_powers: a list with all powers of fractional polynomial terms.
Each entry of the list is named according to the transformation of the
variable.
\item acd: a vector with information for which variables the acd
transformation was applied.
\item x_original: the scaled and shifted input matrix but without
transformations.
\item y: the original outcome variable.
\item x: the final transformed input matrix used to fit the final model.
\item call_mfp: the call to the \code{mfp2()} function.
\item family_string: the family stored as character string.
\item zero: named logical vector indicating, for each variable, whether only
positive values were transformed.
\item catzero: named logical vector indicating which columns in \code{x} treated
nonpositive values as zero and included an additional binary indicator in
the model.
\item catzero_list: A list of binary variables created when \code{catzero} is set to
TRUE. Returns \code{NULL} if \code{catzero} is FALSE.
\item spike_decision: named numeric vector with values 1, 2, or 3 specifying
spike-at-zero handling for each variable. Value 1 includes both the
transformed variable and a binary indicator, 2 disables the spike and binary
indicator, and 3 retains only the binary indicator.
}
The \code{mfp2} object may contain further information depending on family.
}
\description{
Selects the multivariable fractional polynomial (MFP) model that best predicts
the outcome variable. It also supports approximate cumulative
distribution (ACD) transformations for continuous variables, which enable
modeling of sigmoid relationships between predictors \code{x} and the outcome \code{y}
(Royston, 2014; Royston and Sauerbrei, 2016). In addition, it implements
spike-at-zero (SAZ) modeling, a method for appropriately handling
semi-continuous predictors with a non-negligible proportion of zero values
(Becher et al., 2012). The function provides two interfaces for input data:
one for supplying the data matrix \code{x} and the outcome \code{y} directly, where \code{y}
may be a numeric vector for continuous or binary outcomes, or a \code{Surv} object
for Cox proportional hazards models; and another for using a \code{formula} object
together with a dataframe \code{data}. Both interfaces are equivalent in functionality.
}
\section{Methods (by class)}{
\itemize{
\item \code{mfp2(default)}: Default method using input matrix \code{x} and outcome vector \code{y}.

\item \code{mfp2(formula)}: Provides formula interface for \code{mfp2}.

}}
\section{Brief summary of fractional polynomials (FPs)}{


Fractional polynomials (FPs) provide a flexible framework for modeling
nonlinear relationships between a continuous predictor \eqn{x} and an outcome.
In general, we denote an FP of degree \eqn{m} as \eqn{FPm(p_1, \dots, p_m)},
where \eqn{p_1, \dots, p_m} are the selected powers and \eqn{m \ge 1}.

The most commonly used cases are:
\itemize{
\item \strong{FP1:} a single-term transformation, \eqn{FP1(p_1) = \beta_1 x^{p_1}},
representing the simplest FP model.
\item \strong{FP2:} a two-term transformation, \eqn{FP2(p_1, p_2) = \beta_1 x^{p_1} + \beta_2 x^{p_2}},
where \eqn{p_1 \ne p_2}, providing greater flexibility to capture nonlinear
effects.
}

When \eqn{p_1 = p_2} (repeated powers), the FP2 model is defined as
\deqn{FP2(p_1, p_2) = \beta_1 x^{p_1} + \beta_2 x^{p_1} \log(x).}

The powers \eqn{p_1} and \eqn{p_2} are usually chosen from a predefined set
\eqn{S = \{-2, -1, -0.5, 0, 0.5, 1, 2, 3\}}, where a power of 0 indicates
the natural logarithm. The best FP2 model is then selected using a closed
testing procedure that evaluates all 36 pairs of powers \eqn{(p_1, p_2)}.

For further details, see Sauerbrei et al. (2006) and Royston and Sauerbrei (2008).
For the effects of influential points on FP functions, see Sauerbrei et al. (2023).
}

\section{Details on \code{family} option}{


\code{mfp2()} supports the \code{family} argument as used by \code{\link[stats:glm]{stats::glm()}}. Built-in
families can be specified via a character string. For example,
\code{mfp2(..., family = "binomial")} fits a logistic regression model, whereas
\code{mfp2(..., family = "gaussian")} fits a linear regression model using ordinary
least squares.

For Cox proportional hazards models, the response should preferably be a
\code{Surv} object, created with \code{\link[survival:Surv]{survival::Surv()}}, and the \code{family} argument
should be set to \code{"cox"}. Only right-censored data are currently supported.
Stratified Cox models can be specified using the \code{strata} argument, or by
including \code{strata} terms in the model formula when using the formula interface
\code{mfp2.formula}.
}

\section{Details on shifting, scaling, centering}{


Fractional polynomials are defined only for positive variables due to the
use of logarithms and other powers. Thus, \code{mfp2()} estimates shifts for
each variables to ensure positivity or assumes that the variables are
already positive when computing fractional powers of the input variables
in case that shifting is disabled manually.

If the values of the variables are too large or too small, it is important to
conduct variable scaling to reduce the chances of numerical underflow or
overflow which can lead to inaccuracies and difficulties in estimating the
model. Scaling can be done automatically or by directly specifying the
scaling values so that the magnitude of the \code{x} values are not too extreme.
By default scaling factors are estimated by the program as follows.

After adjusting the location of \eqn{x} so that its minimum value is positive,
creating \eqn{x'}, automatic scaling will divide each value of \eqn{x'} by
\eqn{10^p} where the exponent \eqn{p} is given by
\deqn{p = sign(k) \times floor(|k|) \quad \text{where} \quad k = log_{10} (max(x')- min(x'))}

After the final FP powers are estimated, the program backscales \eqn{x'} to
the original scale \eqn{x}, ensuring that the final regression coefficients
are expressed in the original scale of the data. The FP transformation of
\eqn{x} is centered on the mean of the observed values of \eqn{x}. For example,
for the FP1 model \eqn{\beta_0 + \beta_1x^p},the actual model fitted by the
software would be \eqn{\beta'_0 + \beta'_1(x^p-mean(x^p))}. This approach
ensures that the revised constant \eqn{\beta'_0} or baseline hazard function
in a Cox model retains a meaningful interpretation.

So in brief: shifting is required to make input values positive, scaling
helps to bring the values to a reasonable range. Both operations are
conducted before estimating the FP powers for an input variable.
Centering, however, is done after estimating the FP functions for each
variable.

Additionally, any variable marked as \code{zero}, \code{catzero}, or with degrees of
freedom equal to 1 (\code{df = 1}) has its shift automatically set to zero. This
ensures that variables for which transformations are unnecessary like linear
are not artificially shifted.

Centering before estimating the FP powers may result in different powers and
should be avoided. Also see \code{\link[=transform_vector_fp]{transform_vector_fp()}} for some more details.
}

\section{Details on the \code{subset} argument}{

Subsetting in \code{mfp2()} occurs after data pre-processing (shifting, scaling,
or centering) but before model selection and fitting. Specifically, if the
\code{subset} option is used and scale, shift, or centering parameters need to be
estimated, \code{mfp2()} first estimates these parameters using the full dataset
(without subsetting). The subset is then applied before performing model
selection and fitting on the specified portion of the data.

Consequently, subsetting within \code{mfp2()} is not equivalent to subsetting the
data prior to calling the function. It should not be used to implement tasks
such as cross-validation or removal of \code{NA} values, which should be handled
by the user beforehand. The \code{subset} argument is primarily useful when the
same pre-processing should be applied to multiple subsets. For example, one
might estimate separate models for women and men while using identical
data pre-processing (e.g., centering or scaling) across both subsets. In
this case, \code{subset} can restrict model selection to the chosen group while
retaining consistent pre-processing parameters.
}

\section{Details on  approximate cumulative distribution transformation}{


The approximate cumulative distribution (ACD) transformation is a method
to model continuous covariates flexibly in regression models. Instead of
including the raw variable \eqn{X} directly, a smooth function approximating
its empirical cumulative distribution function (ecdf) is used.

\strong{Method}

Let \eqn{x_1, \dots, x_n} be a sample from the distribution of \eqn{X}.
The ACD transformation proceeds in three steps:
\enumerate{
\item \strong{Inverse normal transformation of ranks:}
Compute the rank of each \eqn{x_i} in the sample and transform it using the
standard normal inverse CDF (probit):
\deqn{z_i = \Phi^{-1} \Big( \frac{\text{rank}(x_i) - 0.5}{n} \Big),}
where \eqn{\Phi^{-1}} is the inverse standard normal CDF. This maps the
empirical distribution of \eqn{X} to approximately standard normal values.
\item \strong{Power-linear approximation:}
Fit a one-term fractional polynomial regression of \eqn{z_i} on a shifted
and powered version of \eqn{X}:
\deqn{\hat{z}_i = \hat{\beta}_0 + \hat{\beta}_1 (x_i + \text{shift})^p,}
where \eqn{p} is the best-fitting power, and \eqn{\text{shift}} ensures all
values are positive if necessary. Ordinary least squares is used to estimate
\eqn{\hat{\beta}_0} and \eqn{\hat{\beta}_1}. A power of 0 corresponds to a
log transformation.
\item \strong{Back-transformation to the (0,1) scale:}
The fitted values \eqn{\hat{z}_i} are transformed back to the interval (0,1)
using the standard normal CDF:
\deqn{\text{ACD}(x_i) = a_i = \Phi(\hat{z}_i) = \Phi(\hat{\beta}_0 + \hat{\beta}_1 (x_i + \text{shift})^p),}
producing a smooth approximation of the ecdf.
}

\strong{Interpretation}

The ACD transformation maps \eqn{X} to an approximately uniform scale on (0,1).
When a regression model is specified as
\eqn{E(Y) = \beta_0 + \beta_1 \text{ACD}(X)}, the expected value of \eqn{Y}
changes smoothly from \eqn{\beta_0} at \eqn{\text{ACD}(X) \approx 0}
(corresponding to the minimum of \eqn{X}) to \eqn{\beta_0 + \beta_1} at
\eqn{\text{ACD}(X) \approx 1} (corresponding to the maximum of \eqn{X}).

Because the mapping from \eqn{X} to \eqn{\text{ACD}(X)} is S-shaped—changing
slowly at the extremes and more rapidly in the central range—the resulting
relationship between \eqn{Y} and \eqn{X} is typically nonlinear and
sigmoid-shape. This sigmoid shape cannot be achieved by standard fractional
polynomial (FP) functions.

Intuitively, the ACD transformation “stretches” the middle of \eqn{X}'s
distribution while compressing the tails. A linear effect of
\eqn{\text{ACD}(X)} in the regression thus produces slow changes in \eqn{Y}
for extreme values of \eqn{X} and faster changes for central values,
generating a characteristic sigmoid curve.

Details of the precise definition and some possible uses of the ACD
transformation in a univariate context are given by Royston (2014).

\strong{FP1 with ACD component}

Royston (2014) and Royston and Sauerbrei (2016) describe extending the FP2
family by replacing one FP1 term with an ACD-transformed term:
\deqn{FP1(p_1, p_2) = \beta_1 x^{p_1} + \beta_2 \text{ACD}(x)^{p_2},}
which allows modeling of sigmoid-like effects while maintaining flexibility
similar to standard FP2 functions.

The powers \eqn{p_1} and \eqn{p_2} are chosen from a predefined set
\eqn{S = \{-2, -1, -0.5, 0, 0.5, 1, 2, 3\}}, with 0 corresponding to a
logarithmic transformation. All 64 combinations of \eqn{(p_1, p_2)} are
considered during model selection.

\strong{Model simplification}

After fitting, the chosen FP1+ACD function can be simplified via a function
selection procedure (FSPA) that evaluates six nested sub-families:
\itemize{
\item M1: FP1(p1, p2) (no simplification)
\item M2: FP1(p1, .) (regular FP1 in \eqn{x})
\item M3: FP1(., p2) (FP1 in \eqn{ACD(x)})
\item M4: FP1(1, .) (linear in \eqn{x})
\item M5: FP1(., 1) (linear in \eqn{ACD(x)})
\item M6: null (\eqn{x} omitted)
}

\strong{Closed test procedure to choose final model}

Selection among these six sub-functions is performed by a closed test
procedure known as the function-selection pocedure FSPA.
It maintains the family-wise type 1 error
probability for selecting \eqn{x} at the value determined by the
\code{select} parameter. To obtain a 'final' model, a structured sequence of up
to five tests is carried out, the first at the significance level specified
by the \code{select} parameter, and the remainder at the significance level
provided by the \code{alpha} option.
The sequence of tests is as follows:
\itemize{
\item Test 1: Compare the deviances of models 6 and 1 on 4 d.f.
If not significant then stop and omit \eqn{x}, otherwise continue to step 2.
\item Test 2: Compare the deviances of models 4 and 1 on 3 d.f.
If not significant then accept model 4 and stop. Otherwise, continue to step 3.
\item Test 3: Compare the deviance of models 2 and 1 on 2 d.f.
If not significant then accept model 2 and stop. Otherwise continue to step 4.
\item Test 4: Compare the deviance of models 3 and 1 on 2 d.f.
If significant then model 1 cannot be simplified; accept model 1 and stop.
Otherwise continue to step 5.
\item Test 5: Compare the deviances of models 5 and 3 on 1 d.f.
If significant then model 3 cannot be simplified; accept model 3.
Otherwise, accept model 5. End of procedure.
}
The result is the selection of one of the six models. For details see
Royston and Sauerbrei (2016).

\strong{Sigmoid shapes and the M1–M6 model hierarchy}

Sigmoid-shaped relationships between \eqn{X} and \eqn{Y} occur only when
\eqn{\text{ACD}(X)} is included linearly (power of one). Among the M1–M6 models,
this condition is met by model M5.
}

\section{Details on  spike-at-zero (SAZ) modeling}{

In epidemiological and clinical studies, a continuous covariate \code{x} may have a
mixture of zeros and positive values, which is called a semi-continuous variable.
There is a ‘spike’ at zero in an otherwise continuous distribution. Examples
include occupational exposures (e.g., asbestos) or alcohol/tobacco consumption,
where some individuals have no exposure while others have positive values. When
\code{x = 0} defines a distinct subpopulation, the outcome for these individuals can
be modeled using a binary variable \code{Z}, while positive values are modeled with a
continuous FP function.

\strong{Stage 1: Functional form selection}

A binary indicator \code{Z} is created (\code{Z = 1} if \code{x = 0}, \code{0} otherwise). FP
transformations are applied only to positive values of \code{x}, so there is no need
to shift \code{x}. The user must choose a significance level (\code{select}) if the
criterion is \code{"pvalue"}. If \code{"aic"} or \code{"bic"} is used, the model with the minimum
information criterion is selected. The user must also choose the maximum complexity
of the FP function for \code{x} (default is FP2).

Suppose FP2 is the maximum complexity and \code{criterion = "pvalue"}. The selection
procedure proceeds sequentially as follows:
\enumerate{
\item Compare the most complex model (best FP2 + Z) with the null model
(df = 5: 4 from FP2, 1 from Z). If significant, continue; otherwise, choose the null model.
\item Compare best FP2 + Z versus linear + Z (df = 3). If significant, continue; otherwise, select linear + Z.
\item Compare best FP2 + Z versus best FP1 + Z (df = 2). If significant, retain best FP2 + Z; otherwise, select best FP1 + Z.
}

This ensures that the functional form is selected sequentially, retaining only
models that significantly improve fit, always including \code{Z}. Stage 1 mirrors the
standard MFP function selection process, except that \code{Z} is forced into the model.
To force the SAZ variable into the model, set \code{select = 1} or use the \code{keep}
argument.

\strong{Stage 2: Component assessment}

The selected model from Stage 1 is evaluated to decide which components are
needed. If the null model is selected in Stage 1, Stage 2 is not executed.
Otherwise, suppose the selected model is best FP2 + Z:
\itemize{
\item Test 1: Compare best FP2 + Z versus best FP2 alone to assess the contribution of Z.
\item Test 2: Compare best FP2 + Z versus Z alone to assess the contribution of the FP2 term.
}

Decision rules:
\itemize{
\item If both tests are significant, retain both Z and FP2 in the final model,
because each component adds information beyond the other.
\item If Test 1 is significant but Test 2 is not, retain only Z, because the
spike indicator improves the model while the functional form does not
contribute additional information.
\item If Test 2 is significant but Test 1 is not, retain only FP2, because the
functional form improves the model while the spike indicator does not add
further explanatory value.
\item If neither test is significant, compare the deviances of the Z-only and
FP2-only models. The final model is the one with the smaller deviance,
since it provides the better fit to the data without unnecessary terms.
}

For \code{criterion = "aic"} or \code{criterion = "bic"}, the information criteria for
the three models (FP2 + Z, FP2, and Z only) are compared, and the one with
the minimum value is chosen.
If \eqn{Z} is removed, the spike at zero plays no specific role, and a
standard FP function is selected for the positive values of \code{x}. Conversely,
if the FP function is removed, leaving only \eqn{Z} in the model, the
covariate's effect is entirely captured by the binary indicator. It should
be noted that the presence of \eqn{Z} in Stage 1 may influence the selection
of FP powers; consequently, the final powers may differ from those obtained
in a standard FP analysis where both \code{spike = FALSE} and
\code{catzero = FALSE} are applied.
}

\section{Handling extreme proportions of zeros in spike-at-zero (SAZ) modeling}{

The spike-at-zero (SAZ) approach is meaningful only when the proportion of zeros
in a covariate is moderate, typically ranging from 5\% to 95\%. Covariates with
fewer than 5\% zeros may not contain sufficient information to justify a
separate binary indicator, particularly in small samples where estimation of
separate FP terms could be unstable. Conversely, covariates with more than 95\%
zeros are dominated by the zero values, leaving the positive portion too sparse
for reliable estimation.

In the implementation, the \code{reset_spike} function automatically addresses such
extreme cases. By default, if the proportion of zeros is below 5\% or above 95\%,
the spike is reset to \code{FALSE}, and the variable is treated as a standard
continuous covariate. This ensures that SAZ modeling is applied only when both
the zero and positive portions of the covariate provide sufficient information.
Users may override these thresholds using the \code{min_prop} and \code{max_prop} options.
}

\section{Details on model specification using a \code{formula}}{

\code{mfp2} supports model specification through two interfaces.
The first accepts the design matrix \code{x} together with an outcome object \code{y},
similar to \code{\link[stats:glm]{stats::glm.fit()}} or \code{\link[glmnet:glmnet]{glmnet::glmnet()}}. For generalized linear
models this may be a vector, but in the case of Cox regression \code{y} must be a
two-column survival object (time and event indicator) created using
\code{\link[survival:Surv]{survival::Surv()}}. The second interface follows the formula style used by
functions such as \code{\link[stats:glm]{stats::glm()}} or \code{\link[survival:coxph]{survival::coxph()}}.

Both interfaces are equivalent in functionality; only the details of
specification differ. In the standard interface all details regarding
FP-transformations are given as vectors, while in the formula interface
they are specified using the special \code{fp()} function. The following options
can be set: degrees of freedom (\code{df}), nominal significance level for
variable selection (\code{select}), nominal significance level for functional form
selection (\code{alpha}), shift values (\code{shift}), scale values (\code{scale}),
centering (\code{center}), ACD-transformation (\code{acd}), handling of nonpositive
values (\code{zero}), automatic creation of binary indicators for nonpositive
values (\code{catzero}), and assessment of a potential spike at zero (\code{spike}).
When arguments are supplied both inside \code{fp()} and as global defaults in
\code{mfp2()}, the specifications inside \code{fp()} take precedence. For example, in
\code{mfp2(y ~ fp(x, df = 2), df = 4, data = data)}, the fractional polynomial for
\code{x} is fitted with \code{df = 2}, and the global setting \code{df = 4} is ignored.

The formula may also contain \code{strata} terms to fit stratified Cox models, or
an \code{offset} term to specify a model offset.

Note that for a formula using \code{.}, such as \code{y ~ .} the \code{mfp2()} function may
not fit a linear model, but may perform variable and functional form selection
using FP-transformations, depending on the global default settings of \code{df},
\code{select} and \code{alpha} passed as arguments to \code{mfp2()}. For example, using
\code{y ~ .} with default settings means that \code{mfp2()} will apply FP transformation
with 4 df to all continuous variables and use alpha equal to 0.05 to select
functional forms, along with the selection algorithm with a significance
level of 0.05 for all variables.
}

\section{Handling nonpositive values (\code{zero} and \code{catzero})}{


The \code{zero} and \code{catzero} options provide mechanisms for handling
covariates with nonpositive values in fractional polynomial (FP) models,
especially when those values have a qualitatively different interpretation
than positive ones.

The \code{zero} argument allows fitting FP models using only the positive
values of a covariate, while treating nonpositive values (e.g., zero or
negative) as exactly zero. This is useful when the relationship between the
covariate and the outcome is expected to begin only above zero. For example,
in modeling the effect of cigarette consumption, nonsmokers (zero cigarettes)
may be fundamentally different from smokers. Instead of applying a constant
shift (e.g., adding 1) to all values before transformation, the \code{zero}
argument allows the model to treat zero values as a separate baseline and
apply FP transformations only to the positive values.

The \code{catzero} argument extends this idea by automatically creating a
binary indicator for whether the covariate is positive. Specifically, for
each covariate where \code{catzero = TRUE}, a binary variable \code{Z} is
created such that:

\code{Z = 1} if the covariate value is zero (x = 0)
\code{Z = 0} if the covariate value is positive (x > 0)

This indicator is  included in the model alongside the transformed version
of the covariate. Both are treated as a single predictor during model
selection (if applicable). This approach captures the potential difference
between having a value of zero and having any positive value, while still
allowing flexible modeling of the positive range.

The \code{spike} argument triggers the spike-at-zero (SAZ) algorithm. When
\code{spike = TRUE}, the binary indicator created by \code{catzero} is
formally evaluated together with the FP terms during model selection. When
\code{spike = FALSE} but \code{catzero = TRUE}, the binary indicator is
included in the model without SAZ testing.

This methodology is based on work by Royston and Sauerbrei (2008, Section 4.15)
and is particularly relevant in epidemiological contexts where exposure may
have a threshold effect.
}

\section{Compatibility with \code{mfp} package}{

\code{mfp2} is an extension of the \code{mfp} package and can be used to reproduce
the results from a model fitted by \code{mfp}. Since both packages implement the
MFP algorithm, they use functions with the same names (e.g \code{fp()}). Therefore,
if you load both packages using a call to \code{library}, there will
be namespace conflicts and only the functions from the package loaded last
will work properly.
}

\section{Convergence and Troubleshooting}{

Typically, \code{mfp2} requires two to five cycles to achieve convergence. Lack of
convergence involves oscillation between two or more models and is extremely
rare. If convergence problems occur, consider adjusting the nominal
significance levels for variable selection (\code{select}) or functional form
selection (\code{alpha})
}

\examples{

# Gaussian model
data("prostate")
x = as.matrix(prostate[,2:8])
y = as.numeric(prostate$lpsa)
# default interface
fit1 = mfp2(x, y, verbose = FALSE)
fit1$fp_terms
fracplot(fit1) # generate plots
summary(fit1)
# formula interface
fit1b = mfp2(lpsa ~ fp(age) + fp(svi, df = 1) + fp(pgg45) + fp(cavol) + fp(weight) +
fp(bph) + fp(cp), data = prostate)

# logistic regression model
data("pima")
xx <- as.matrix(pima[, 2:9])
yy <- as.vector(pima$y)
fit2 <- mfp2(xx, yy, family = "binomial", verbose = FALSE)
fit2$fp_terms

# Cox regression model
data("gbsg")
# create dummy variable for grade using ordinal coding
gbsg <- create_dummy_variables(gbsg, var_ordinal = "grade", drop_variables = TRUE)
xd <- as.matrix(gbsg[, -c(1, 6, 10, 11)])
yd <- survival::Surv(gbsg$rectime, gbsg$censrec)
# fit mfp and keep hormon in the model
fit3 <- mfp2(xd, yd, family = "cox", keep = "hormon", verbose = FALSE)
fit3$fp_terms

}
\references{
Royston, P. and Sauerbrei, W., 2008. \emph{Multivariable Model - Building:
A Pragmatic Approach to Regression Anaylsis based on Fractional Polynomials
for Modelling Continuous Variables. John Wiley & Sons.}\cr

Sauerbrei, W., Meier-Hirmer, C., Benner, A. and Royston, P., 2006.
\emph{Multivariable regression model building by using fractional
polynomials: Description of SAS, STATA and R programs.
Comput Stat Data Anal, 50(12): 3464-85.}\cr

Royston, P. 2014. \emph{A smooth covariate rank transformation for use in
regression models with a sigmoid dose-response function.
Stata Journal 14(2): 329-341.}\cr

Royston, P. and Sauerbrei, W., 2016. \emph{mfpa: Extension of mfp using the
ACD covariate transformation for enhanced parametric multivariable modeling.
The Stata Journal, 16(1), pp.72-87.}\cr

Sauerbrei, W. and Royston, P., 1999. \emph{Building multivariable prognostic
and diagnostic models: transformation of the predictors by using fractional
polynomials. J Roy Stat Soc a Sta, 162:71-94.}\cr

Sauerbrei, W., Kipruto, E. and Balmford, J., 2023. \emph{Effects of influential
points and sample size on the selection and replicability of multivariable
fractional polynomial models. Diagnostic and Prognostic Research, 7(1), p.7.}\cr

Becher, H., Lorenz, E., Royston, P. and Sauerbrei, W., 2012. \emph{Analysing
covariates with spike at zero: a modified FP procedure and conceptual issues.
Biometrical journal, 54(5), pp.686-700.}\cr

Lorenz, E., Jenkner, C., Sauerbrei, W. and Becher, H., 2019. \emph{Modeling exposures
with a spike at zero: simulation study and practical application to survival data.
Biostatistics & Epidemiology, 3(1), pp.23-37.}
}
\seealso{
\code{\link[=summary.mfp2]{summary.mfp2()}}, \code{\link[=coef.mfp2]{coef.mfp2()}}, \code{\link[=predict.mfp2]{predict.mfp2()}}, \code{\link[=fp]{fp()}}
}
