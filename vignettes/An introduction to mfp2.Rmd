---
title: "mfp2 package"
author:
- Edwin Kipruto
- Michael Kammer
- Patrick Royston
- Willi Sauerbrei
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: '3'
    number_sections: yes
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    fig_caption: yes
    toc: yes
    toc_depth: 3
    number_sections: yes
editor_options:
  markdown:
    wrap: sentence
    
---

<!-- justify text in the entire document-->
<style>
body {
  text-align: justify;
}

figcaption {
  text-align: justify;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

## Overview of Multivariable Fractional Polynomial(MFP)
Multivariable regression models are widely used across various fields of science 
where empirical data is analyzed. In model building, many researchers
often assume a linear function for continuous variables, sometimes after 
applying “standard” transformations such as logarithmic, or divide the variable
into several categories. However, assuming linearity without considering 
non-linear relationships may hinder the detection of stronger effects or even 
cause the effects to be mis-modeled. Categorizing continuous variables, which 
results in modeling implausible step functions, is a common practice but widely
criticized (Sauerbrei et al. 2023; Royston et al. 2006). 


When building a descriptive model with the aim of identifying predictors of an 
outcome and understanding the the relationship between the predictors and the 
outcome, two components are often considered: variable selection, which involves
identifying the subset of “important” predictors, and identification of possible
non-linearity in continuous predictors. 

The MFP approach has been proposed as a pragmatic method for dealing with
non-linearity in multivariable model-building. This approach retains continuous
predictors as continuous, identifies non-linear functions if sufficiently 
supported by the data, and eliminates weakly influential predictors using 
backward elimination (BE). Despite its simplicity and ease of understanding for
researchers familiar with regression models, the selected models often capture
the essential information from the data. The MFP models are relatively 
straightforward to interpret and report, which is essential for their 
transportability and practical applicability. In summary, the MFP procedure 
combines:

* variable selection through backward elimination (BE) with\
* Selection of fractional polynomial (FP) functions for continuous variables

The analyst must decide on a nominal significance level $(\alpha)$ for both 
components. The choice of these two significance levels has a strong influence 
on the complexity of the final model. While it is possible to use the same 
$\alpha$ level for both components, they can also differ. The decision regarding
these significance levels heavily depends on the specific aim of the analysis.

Section 1.2 provides an overview of fractional polynomial functions for a single
continuous variable in the model, including the function selection procedure (FSP).
In Section 1.3, the MFP approach is described, focusing on models that involve 
two or more variables. Section 2 covers the installation process of our package
and provides instructions for utilizing it in various linear regression models,
such as linear, logistic, poisson, and cox regressions. Section 3 presents a 
comparison between our package and other R packages that implement MFP. 
Section 4 introduces an extension of MFP using the approximate cumulative 
distribution (ACD) transformation of a continuous covariate. This extension 
allows for modeling a sigmoid relationship between covariates and an outcome
variable. Subsection 4.1 describes the function selection procedure with ACD 
transformation (FSPA), while section 4.2 offers a guide on how to implement 
MFPA using our package.. Lastly, Section 5 describes an additional extension of
MFP that is not currently implemented in our package but is available in the 
STATA software.

For more comprehensive information about MFP and its extensions, please visit
our website at https://mfp.imbi.uni-freiburg.de/.


## Fractional polynomial models for a continuous variable

Suppose that we have an outcome variable, a single continuous covariate x, and 
a regression model relating them. A starting point is the straight-line model,
$\beta_1x$ (for simplicity, we suppress the constant term, $\beta_0$). Often, a
straight line is an adequate description of the relationship, but other models
should be investigated for possible improvements in ﬁt. A simple extension of 
the straight line is a power transformation model, $\beta_1x^{p}$. The latter 
model has often been used by practitioners in an ad hoc way, utilizing diﬀerent
choices of p. Royston and Altman (1994) formalized the model by calling it a
ﬁrst-degree fractional polynomial or FP1 function. The power p is chosen from a 
pragmatically restricted set of eight elements: 
S = {−2, − 1, − 0.5, 0, 0.5, 1, 2, 3}, where $x^0$ denotes natural logarithm  of
x, $log (x)$.

As with polynomial regression, extension from one-term FP1 functions to more 
complex and ﬂexible two-term FP2 functions is straightforward.
The quadratic function $\beta_1x^1 + \beta_2x^2$ is written as 
$\beta_1x^{p1} + \beta_2x^{p2}$ in FP terminology. The powers $p1=1$ and $p2=2$ 
are members of S. Royston and Altman extended the class of FP2 functions with
different powers to cases with equal powers ($p1=p2=p$) by defining them as
$\beta_1x^p + \beta_2x^p log(x)$. These are known as repeated-powers functions.
Detailed definition of FP functions or models is given in Section 4.3.1 of 
Royston and Sauerbrei (2008). For formal deﬁnitions, we use notation from 
Royston and Sauerbrei (2008). Throughout the rest of this article, we use 
abbreviations (R&S, year) and (S&R, year) for papers published by these two author.

FP1 functions are always monotonic and those with power $p < 0$ have an asymptote
as $x\rightarrow \infty$. FP2 functions may be monotonic or unimodal (i.e., 
have one maximum or one minimum for some positive values of x), and they have an
asymptote as $x\rightarrow \infty$ when both $p1$ and $p2$ are negative.
For more details, see R&S (2008), Section 4.4.
Figure 1 shows FP1 and some FP2 curves. The subset of FP2 powers is chosen to 
illustrate the ﬂexibility available with a few pairs of powers ($p1, p2$).

In total, there are 44 models available within the set of FP powers (S),
consisting of 8 FP1 models and 36 FP2 models. Although the allowed class of FP
functions may seem limited, it encompasses a wide range of diverse shapes. 
This is illustrated in Figure 1, with the left panel displaying eight FP1 powers
and the middle panel depicting a subset of FP2 powers. The right panel 
demonstrates the variations in shape for a fixed FP2 power (-2, 2) but different
regression coefficients.

Based on extensive experience with real data and several simulation studies, 
FP1 and FP2 are generally considered adequate in the context of multivariable 
model building, particularly when variable selection and functional forms is 
required. The content of this article has been previously published in two 
encyclopedia articles (Sauerbrei and Royston, 2011; Sauerbrei and Royston, 2016).


```{r, echo=FALSE,results='hide'}
x <- seq(0.05, 1.05, length.out = 1000)
funx <- function(x, power){
  ifelse(power==rep(0,length(x)),log(x), x^power)
}
funx(x = x, power = -2)

s <- c(-2, -1, -0.5, 0, 0.5, 1, 2, 3)
# transform x using the powers in s
outx = lapply(s, function(s) funx(x = x, power = s))
# multiply the first 3 with -1 so that the function increase rather than decrease
# due to negative powers. these are betas i,e y = beta*x^p
k <- c(-1, -1, -1, 1, 1, 1, 1, 1)
datx = matrix(unlist(outx), ncol = length(s))
datax = datx%*%diag(k)
head(datax)
# standardize the data so that y is in the same range
dataxx = apply(datax, 2,function(x) (x-min(x))/(max(x)-min(x)))
colnames(dataxx) <- c(paste0("x",1:length(s)))
head(dataxx)
dataxx <- as.data.frame(dataxx)
dataxx$x <- x
```

```{r, echo=FALSE,results='hide'}
library(ggplot2)
# Different FP2 functions
# Define functions
f1 <- function(x) 3 - 10*x^2 + 4*x^3
f2 <- function(x) 20 - 15.4*x^2 + 4*x^3
f3 <- function(x) -20 + 6*log(x) + 6*log(x)*log(x)
f4 <- function(x) 20 + 0.3*(x^-2) - 4*(x^-1)
f5 <- function(x) -10 + 5*(x^0.5) + 14*(x^-0.5)
f6 <- function(x) 33 + 19*log(x) - 7*(x^2)
f7 <- function(x) -10 + 10*(x-1.5) + 10*(x-1.5)^2

# Create data frames for each function
x = seq(0.1, 3, by = 0.01)
df1 <- data.frame(x = x, y = f1(x))
df2 <- data.frame(x = x, y = f2(x))
df3 <- data.frame(x = x, y = f3(x))
df4 <- data.frame(x = x, y = f4(x))
df5 <- data.frame(x = x, y = f5(x))
df6 <- data.frame(x = x, y = f6(x))
df7 <- data.frame(x = x, y = f7(x))

##############################################################################
# Fixed FP2 POWER TERMS (-2, 2) 
# ADAPTED FROM ROYSTON STATA CODES. SEE FIGURE 4.5 IN HIS BOOK R&S 2008
    x = (1:400)/10+10
    # Generate additional variables
    x2 <- x^2
    x_2 <- 1/x2
    x_1 <- 1/x
    x05 <- sqrt(x)
    x_05 <- 1/x05
    x3 <- x*x2
    x0 <- log(x)
    y1 <- scale(x)
    y2 <- scale(x2)
    y3 <- scale(x_2)
    y4 <- scale(x_1)
    y5 <- scale(x05)
    y6 <- scale(x_05)
    y7 <- scale(x3)
    y8 <- scale(x0)
    # Generate FP2 curves for -2, 2
    f1 <- scale(10 + y3 - 10*y2)
    f2 <- scale(10 + y3 - 5*y2)
    f3 <- scale(10 + y3 - 2*y2)
    f4 <- scale(10 + y3 - 0.5*y2)
    f5 <- scale(10 + y3 - 0.05*y2)
    f6 <- scale(10 + y3 + 10*y2)
    f7 <- scale(10 + y3 + 5*y2)
    f8 <- scale(10 + y3 + 2*y2)
    f9 <- scale(10 + y3 + 0.5*y2)
    f10 <- scale(10 + y3 + 0.05*y2)
    f11 <- scale(10 + y2 - 10*y3)
    f12 <- scale(10 + y2 - 5*y3)
    f13 <- scale(10 + y2 - 2*y3)
    f14 <- scale(10 + y2 - 0.5*y3)
    f15 <- scale(10 + y2 - 0.05*y3)
    f16 <- scale(10 + y2 + 10*y3)
    f17<-scale(10+y2+5*y3)
    f18<-scale(10+y2+2*y3)
    f19<-scale(10+y2+0.5*y3)
    f20<-scale(10+y2+0.05*y3)
      
    df <- data.frame(x, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f17, f18, f19, f20)
    df <- tidyr::pivot_longer(df, cols = -x, names_to = "curve", values_to = "y")
    library(RColorBrewer)
    n <- 20
    colrs <- brewer.pal.info[brewer.pal.info$colorblind == TRUE, ]
    col_vec = unlist(mapply(brewer.pal, colrs$maxcolors, rownames(colrs)))
    col <- sample(col_vec, n)
    col = c('#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000')
```  

```{r, echo=FALSE, fig.show='hide'}
colx <- randomcoloR::distinctColorPalette(8)
linewd=0.7
library(ggplot2)
# 8 fp1
p1 =  ggplot(dataxx, aes(x)) + 
  geom_line(aes(y = x1, colour = "x1"), linewidth = 0.7) + 
  geom_line(aes(y = x2, colour = "x2"), linewidth = linewd) + 
  geom_line(aes(y = x3, colour = "x3"), linewidth = linewd) +
  geom_line(aes(y = x4, colour = "x4"), linewidth = linewd) +
  geom_line(aes(y = x5, colour = "x5"), linewidth = linewd) +
  geom_line(aes(y = x6, colour = "x6"), linewidth = linewd) +
  geom_line(aes(y = x7, colour = "x7"), linewidth = linewd) +
  geom_line(aes(y = x8, colour = "x8"), linewidth = linewd) +
  labs(x = "x", y = "f(x)", color = "Power") +
  geom_text(aes(x = 0.12, y = 0.95, label = "(-2)"), size = 5, color =  colx[1]) +
  geom_text(aes(x = 0.25, y = 0.9, label = "(-1)"),size = 5, color =  colx[2]) +
  geom_text(aes(x = 0.375, y = 0.87, label = "(-0.5)"),size = 5, color = colx[3]) +
  geom_text(aes(x = 0.5, y = 0.82, label = "(0)"),size = 5, color =  colx[4]) +
  geom_text(aes(x = 0.5, y = 0.675, label = "(0.5)"),size = 5, color =  colx[5]) +
  geom_text(aes(x = 0.5, y = 0.54, label = "(1)"),size = 5, color =  colx[6]) +
  geom_text(aes(x = 0.675, y = 0.5, label = "(2)"),size = 5, color =  colx[7]) +
  geom_text(aes(x = 0.75, y = 0.275, label = "(3)"),size = 5, color =  colx[8]) +
  theme_bw() +  theme(legend.position = "none")
```

```{r, echo=FALSE, fig.show='hide'}
# Plot functions
p2 = ggplot() +
  geom_line(data = df1, aes(x = x, y = y), color = "#e41a1c") +
  geom_line(data = df2, aes(x = x, y = y), color = "#377eb8") +
  geom_line(data = df3, aes(x = x, y = y), color = "#4daf4a") +
  geom_line(data = df4, aes(x = x, y = y), color = "#984ea3") +
  geom_line(data = df5, aes(x = x, y = y), color = "#ff7f00") +
  geom_line(data = df6, aes(x = x, y = y), color = "#FF00FF") +
  geom_line(data = df7, aes(x = x, y = y), color = "#a65628") +
  scale_x_continuous(limits = c(0, 3)) +
  scale_y_continuous(expand = c(0, 0), limits = c(-25,40)) + theme_classic() +
  geom_text(aes(x = 0.75, y = 2.4,size = 5, label = "(2, 3)"), color = "#e41a1c") +
  geom_text(aes(x = 1.6, y =1.95,size = 5, label = "(2, 3)"), color = "#377eb8")+
  geom_text(aes(x = 0.7, y = -18,size = 5, label = "(0, 0)"), color = "#4daf4a") +
  geom_text(aes(x = 1.25, y = 20,size = 5, label = "(-2, -1)"), color = "#984ea3") +
  geom_text(aes(x = 1.3, y = 12,size = 5, label = "(-0.5, 0.5)"), color = "#ff7f00") +
  geom_text(aes(x = 1.25, y = 29.5,size = 5, label = "(0, 2)"), color = "#FF00FF") +
  geom_text(aes(x = 1, y = -9.5,size = 5, label = "(1, 2)"), color = "#a65628") +
  ylab("f(x)") + theme_bw() +  theme(legend.position = "none") + theme(axis.title.y = element_blank())
```

```{r, echo=FALSE, fig.show='hide'}
p3 =  ggplot(df, aes(x, y, color = curve)) +
      geom_line()  + theme_classic() +
     theme(
       legend.position = "none",
       axis.ticks = element_blank(),
       axis.text.y = element_blank(),
       axis.title=element_text(size=18),
       axis.text.x = element_blank()) +
      ylab("f(x)") + theme_bw() +
     geom_text(aes(x = 45, y = 4.3, label = "(-2, 2)"),size = 5, color = "black") +
   theme(legend.position = "none") + theme(axis.title.y = element_blank())
```

```{r, echo=FALSE, fig.width=10, fig.height=6, out.width="100%", fig.align='center',fig.cap="Figure 1. Examples of FP1 curves (left) and FP2 curves (middle) are shown for different powers. The right panel illustrates FP2 powers (-2, 2) with different regression coefficients"}
# COMBINE THE TWO PLOTS
patchwork::wrap_plots(p1,p2,p3, ncol=3, widths = 10,heights = 4)

    # (figure =ggpubr::ggarrange(p1,p2,p3,ncol = 3, nrow = 1, widths = 10,heights = 6, common.legend = F, legend = "none", vjust = 2))

```

#### Function selection procedure (FSP)

Choosing the best FP1 or FP2 function by grid search, minimizing the deviance (minus twice the maximized log-likelihood), is straightforward.
However, having a suitable default function is important for increasing the parsimony, stability, and general usefulness of selected functions.
In most of the algorithms implementing fractional polynomial (FP) modeling, the default function is linear -- arguably, a natural choice.
Therefore, unless the data support a more complex FP function, a straight line model is chosen.
There are occasional exceptions; for example, in modeling time-varying regression coeﬃcients in the Cox model, Sauerbrei et al. (2007) chose a default time ($t$) transformation of $log (t)$ rather than $t$.
It can be assumed that deviance diﬀerence between an FPm and an FP (m−1) model is distributed approximately as central $𝜒2$ on 2 degrees of freedom (d.f.) (R&S 2008, Chapter 4.9; Ambler and Royston (2001).
To select a speciﬁc function, a closed test procedure (other procedures had been proposed before) was proposed (R&S 2008, Section 4.10).
The complexity of the ﬁnally chosen function is predicated on preliminary decisions as to the nominal p value (𝛼) and the degree (m) of the most complex FP model allowed.
Typical choices are 𝛼 = 0.05 and FP2 (m = 2).
We illustrate the strategy for m = 2, which runs as follows:

1.  Test the best FP2 model for x at the 𝛼 signiﬁcance level against the null model using 4 d.f. If the test is not signiﬁcant, stop and conclude that the eﬀect of x is "not signiﬁcant" at the 𝛼 level. Otherwise continue.
2.  Test the best FP2 for x against a straight line at the 𝛼 level using 3 d.f. If the test is not signiﬁcant, stop, the ﬁnal model being a straight line. Otherwise continue.
3.  Test the best FP2 for x against the best FP1 at the 𝛼 level using 2 d.f. If the test is not signiﬁcant, the ﬁnal model is FP1, otherwise, the ﬁnal model is FP2. This marks the end of procedure.

The test at step 1 is of overall association of the outcome with x.
The test at step 2 examines the evidence for nonlinearity.
The test at step 3 chooses between a simpler or more complex nonlinear model.

## Multivariable fractional polynomial (MFP) procedure

When developing a multivariable model with a relatively large number of candidate covariates (say 20, we are not envisaging the case of high-dimensional data), an important distinction is between descriptive, predictive and explanatory modelling (Shmueli, 2010).
MFP was mainly developed for descriptive modelling, aiming to capture the data structure parsimoniously.
Nevertheless, a suitable descriptive model often has a fit similar to a model whose aim is good prediction.
In some fields, the term explanatory modelling is used exclusively for testing causal theory.
Unlike developing a predictive model based on acceptable statistical criteria, developing a model suitable for description is much more challenging (Sauerbrei et al., 2015).

In many areas of science, the main interest often lies in the identification of inﬂuential variables and determination of appropriate functional forms for continuous variables.
Often, linearity is presumed without checking this important assumption, and much better-ﬁtting nonlinear functions may not be considered.
The MFP procedure was proposed as a pragmatic strategy to investigate whether nonlinear functions can improve the model ﬁt (R&S, 2008; S&R, 1999).
MFP combines backward elimination (BE) for the selection of variables with a systematic search for possible nonlinearity by the function selection procedure (FSP).
The extension is feasible with any type of regression model to which BE is applicable.
When developing models for description, it is important to consider factors such as model stability, generalizability, and practical usefulness.
The philosophy behind MFP modeling is to create interpretable and relatively simple models (Sauerbrei et al 2007).
Consequently, an analyst using MFP should be less concerned about failing to include variables with a weak eﬀect or failing to identify minor curvature in a functional form of a continuous covariate.
Modiﬁcations that may improve MFP models are combination with post-estimation shrinkage (Dunkler et al., 2016, R-package shrink) and a more systematic check for overlooked local features (Binder and Sauerbrei, 2010, currently not implemented
in our package).Successful use of MFP requires only general knowledge about building regression models.

Two nominal signiﬁcance level values are the main tuning parameters: $\alpha_1$ for selecting variables with BE (in the ﬁrst step of the FSP) and $\alpha_2$ for comparing the ﬁt of functions within the FSP.
Often, $\alpha_1=\alpha_2$ is a good choice.
If available, subject-matter knowledge should replace or at least guide data-dependent model choice.
Only minor modiﬁcations are required to incorporate various types of subject-matter knowledge into MFP modeling.
For a detailed example, see S&R (1999).
Recommendations for practitioners of MFP modeling are given in Sauerbrei et al. (2007b) and in R&S (2008, Section 12.2).

### MFP -- Key Issues and Approaches to Handling Them

Mainly focusing on the FP component, we brieﬂy mention key issues of MFP modeling and refer to the literature for further reading.
Regarding variable selection, we have summarized relevant issues and provided arguments for backward elimination as our preferred strategy (R&S 2008, Chapter 2).
Even when a search for model improvement using a nonlinear function is not considered, that is, all functions are assumed linear, it is infeasible to derive a suitable and stable model for description in small datasets.
Below we provide some information about sample size needed, but implicitly we assume that the sample size is "suﬃcient".

#### The variable has to be positive

The class of FP1 and FP2 functions includes a log and other transformations which require that the continuous variable must be positive.
A preliminary origin-shift transformation can be applied (R&S 2008, Chapters 4.7 and 11).
For variables with a "spike" of probability mass at zero, a binary indicator variable may be added to the model and the FSP may be modiﬁed accordingly (Royston et al., 2010; Becher et al., 2012; Lorenz et al., 2018).

#### Sample size, influential observations and replicability of MFP models

All statistical models are potentially adversely aﬀected by inﬂuential observations or "outliers".
However, compared with models that comprise only linear functions, the situation may be more critical for FP functions because logarithmic or negative power transformations may produce extreme functional estimates at small values of x.
Conversely, the same may happen with large positive powers at large values of x.
Such transformations may create inﬂuential observations that may affect parts of the FSP.
To mitigate the impact of influential observations, it is important to assess the robustness of FP functions.
Some suggestions for investigating inﬂuential points (IPs) and handling such issues in MFP modeling can be found in R&S (2008, Chapters 5 and 10) and their paper on improving the robustness of FP models (R&S, 2007).
Using synthetic data, a more detailed investigation of IPs is given in Sauerbrei et al. (2023).
The authors conclude that for smaller sample sizes, IPs and low power are important reasons that the MFP approach may not be able to identify underlying functional relationships for continuous variables and selected models might differ substantially from the true model.
However, for larger sample sizes (about 50 or more observations per variable) a carefully conducted MFP analysis is often a suitable way to select a multivariable regression model which includes continuous variables. Figure 2 illustrates the effects of influential observation 151 on the art dataset. The variable of interest is x5 with extremely large values, and the outcome is a continuous variable. The inclusion of observation 151 in the data results in the selection of the FP2 function, while its elimination leads to the selection of the FP1 function. Therefore, it is sufficient to describe variable x5 using a simpler FP1 function rather than a complex FP2 function. For more details, refer to Sauerbrei et al. (2023).
```{r, echo=FALSE,results='hide'}
library(mfp2)
data("art")
fit1 <- mfp2::mfp2(y~fp(x5), data = art)
fit2 <- mfp2::mfp2(y~fp(x5), data = art[-151,])

```

```{r, echo=FALSE, fig.show='hide'}
f1 <- mfp2::fracplot(fit1, terms = "x5", terms_seq = "equi")
f2 <- mfp2::fracplot(fit2, terms = "x5", terms_seq = "equi")

```

```{r, echo=FALSE, fig.show='hide'}
f1 <- mfp2::fracplot(fit1, terms = "x5", terms_seq = "equi", shape = 16)
f1 <- f1[[1]] + ylab("y")
f2 <- mfp2::fracplot(fit2, terms = "x5", terms_seq = "equi", shape = 16)
f2 <- f2[[1]] + ylab("y")
```

```{r, echo=FALSE, fig.width=10, fig.height=6, out.width="100%", fig.align='center',fig.cap="Figure 2. Examples of FP1 curves (left) and FP2 curves (middle) are shown for different powers. The right panel illustrates FP2 powers (-2, 2) with different regression coefficients"}
# COMBINE THE TWO PLOTS
patchwork::wrap_plots(f1,f2, ncol=2, widths = 10,heights = 4)

```
# Installation
To install the `mfp2` package, enter the following command in the R console:
```{r, eval=FALSE}
install.packages("mfp2", repos = "??")
```

## Quick Start
The purpose of this section is to provide users with a comprehensive understanding of the mfp2 package. We will offer a concise overview of its key functions, fundamental operations, and resulting outputs. By the end of this section, users will have a clearer understanding of the available functions and be able to identify the appropriate ones for their needs. Additionally, we will delve into each function in detail, highlighting their specific capabilities and potential use cases. This will provide users with a deeper understanding of the package's functionality. The package includes a built-in dataset that is specifically designed for analysis within the `mfp2` framework. This dataset is readily available and can be accessed directly from the package.

To begin, let's load the `mfp2` package:
```{r}
library(mfp2)
```

Load the art dataset from the `mfp2` package

```{r}
data("art")
head(art)
x <- as.matrix(art[,c(2:4,5:8,10:14)])
y <- art$y
```
The default model used in the package is the Guassian linear model or "least squares", which we will demonstrate in this section. We load a set of data created beforehand for illustration:


We fit the model using the most basic call to  `mfp2`.
```{r}
fit <- mfp2(x, y)
```

## Linear Regression

Motivating example (extract more information from the website) 1.
Motivating example Multivariable model--building with continuous predictors

Should we assume linear functional relationships or check whether a non-linear function fits substantially better?

Influence of 7 potential predictors of log prostate-specific antigen (log PSA) in 97 patients with prostate cancer.
A linear regression model (normal-errors regression) seems sensible as the outcome, log PSA, is continuous.
For more details see Appendix A.2.5 in our book.

The two main questions are:

    include all variables and estimate corresponding parameters, or eliminate variables with at most weak effects?
    assume linear relationships or allow non-linear functions?

Decisions depend on the aim of the model: prediction or explanation?
Prediction aims to predict the outcome as accurately as possible, with little regard for the detailed components of the model; explanation seeks a good fit to the data, but further demands interpretable functions, and a model that as far as possible is consistent with subject-matter knowledge.
Generally, our stance is that explanation is the more informative approach.

In what follows, the term 'full model' means the model that includes all candidate predictors, whether statistically significant or not, and retains all continuous predictors as linear functions.
BE(0.05) means the linear model selected by backward elimination at the 0.05 significance level.
MFP(0.05) means the MFP model with functions and variables selected at the 0.05 significance level.
It is also possible using different significance level for the two components.
MFP(0.05, 0.01) means that variables are selected at 0.05 and functions at 0.01 level.
Furthermore, it is possible choosing specific significance levels for each variable.

### Gaussian family

## Logistic Regression

## Poisson regression

## Survival data

### Fractional polynomials are unsuitable for modeling some types of functions

#### MFPA to model sigmoid functions

Sigmoid (doubly asymptotic) functions are not represented in the class of standard FP functions.
Royston (2014) introduced the approximate cumulative distribution (ACD) transformation of a continuous covariate x as a route toward modeling a sigmoid relationship between x and an outcome variable.
In addition, R&S (2016) proposed the MFPA procedure, which extends standard MFP by permitting selection of sigmoid functions derived from the ACD transformation when supported by suﬃciently strongly evidence in the data.

#### Local features

Unlike splines which have a local interpretation of the fitted function, FPs provide a curve with a global interpretation.
To investigate possible "overlooked" local features of an FP function, Binder and Sauerbrei (2010) conducted a systematic analysis of model ﬁts obtained by MFP.
If local features are detected by their MFP + L procedure, statistically signiﬁcant local polynomials are then parsimoniously added to the predictor from MFP.
This enables the identification and incorporation of local features that may have been missed by the global FP function.
So far not implemented.

#### Improved fit by more complex functions

Lack of ﬁt is a potential issue for any model.
Possible reasons are manifold, and it is not usually obvious how best to improve the model.
In the context of (FP) functions, ﬁt may be improved by applying a preliminary transformation or using higher order fractional polynomials (R&S 2008, Section 5), eg.
FP3).
However, for more than two decades of practical experience with data from the health sciences, higher order FPs (larger than 2) were hardly ever required to improve a model.
Obviously, lack of ﬁt may also point to overlooked covariate interactions or other types of mismodeling.

### Parameter estimates are likely to be biased

For all types of regression models, data-dependent model building introduces selection bias in parameter estimates.
Shrinkage factors oﬀer a possible way to try to correct for this bias (R&S 2008, Chapter 2.8; Sauerbrei, 1999).
For parameters that are highly correlated or structurally associated, such as dummy variables coding a categorical variable or several parameters describing a nonlinear (FP2) function, the approach has been extended to joint shrinkage factors (Dunkler et al., 2016).\

In addition, data-dependent search for the best-fitting functional form (determination of power terms and corresponding parameter estimates) implies that estimated standard errors and conﬁdence intervals tend to be too small because inference is done as if the model had been prespeciﬁed (sometimes called naive estimates).
The uncertainty of the selection process is ignored.
The general weakness of all strategies that derive a model in a data-dependent way has been known for a long time.
More than two decades ago, Breiman (1992) called this a "quiet scandal".
To tackle the issue, one could improve interval estimates using approaches based on the bootstrap (R&S 2008, Chapter 6.6) or the model uncertainty concept and model averaging (Draper, 1995; Faes et al., 2007).

### Extensions of MFP to investigate for interactions

Substantia shortening required.
For more details see the website and papers cited.
Stata programs for MFPI and MFPIgen are available (<https://mfp.imbi.uni-freiburg.de/>)\
MFP was developed to select main effects of covariates on the outcome.
If a variable $x_2$ explains (at least partially) the relationship between a covariate $x_1$ and the outcome y then confounding is present.
Another important issue in multivariable modeling is interaction between two or more covariates.
An interaction between $x_1$ and $x_2$ is present if $x_2$ modifies the relationship between x1 and the outcome.
This means that the effect of $x_1$ is different in subgroups determined by $x_2$.
Extensions of MFP have been proposed to handle two-way interactions involving at least one continuous covariate (R&S, 2004; R&S 2008, Chapter 7).\

To investigate for a possible interaction between a continuous covariate and two treatment arms in a randomized controlled trial, the multivariable fractional polynomial interaction (MFPI) procedure was introduced (R&S, 2004).
In a first step, the FP class is used to model the prognostic effect of the continuous variable separately in the two treatment arms, usually under some restrictions such as the same power terms in each arm.
In a second step, a test for the equality of the prognostic functions is conducted.
If significant, an interaction is present and the difference between two functions estimates the influence of the prognostic factor on the effect of treatment.
The difference function is called a treatment effect function and should be plotted.
For interpretation, it is important to distinguish between the two cases of a predefined hypothesis and of searching for hypotheses (R&S 2008; R&S 2004).\

In a large simulation study, R&S (2013; 2014) evaluated the significance levels of 21 methods for investigating interactions between a binary treatment effect and a continuous covariate in a randomized controlled trial.
They concluded that the results provided sufficient evidence to recommend the MFPI procedure as a suitable approach to investigate interactions of treatment with a continuous variable.
For more than 2 groups, extensions to investigate continuous by categorical interactions are immediate.
Furthermore, MFPI allows investigation of treatment-covariate interactions in models with or without adjustment for other covariates.
The adjustment for other covariates enables the use of the procedure also in observational studies.
Continuous-by-continuous interactions are important in observational studies.
A popular approach is to assume linearity for both variables and test the multiplicative term for significance.
However, the model may fit poorly if one or both of the main effects is non-linear.
In R&S (2008, Chapter 7) an extension of MFPI, known as MFPIgen, was introduced.
Products of selected main effect FP functions are considered as candidates for an interaction between a pair of continuous variables.
Several continuous variables are usually available, and a test of interaction is conducted for each such pair.
If more than one interaction is detected, interactions are added to the main-effects model in a step-up manner.
The MFPT(ime) algorithm (Sauerbrei et al 2007) combines selection of variables and of the functional form for continuous variables with determination of time-varying effects in a Cox proportional hazards model for survival data.
A procedure analogous to the FSP was suggested for investigating whether the effect of a variable varies in time, i.e. whether a time-by-covariate interaction is present.
Buchholz and Sauerbrei (2011) compared procedures to assess non-linear and time-varying effects in multivariable models for survival data.
They found that assessing time-varying effects depends on issues such as modeling the functional form for a continuous covariate and omitting other covariates.
Among the approaches investigated, MFPT seems to be preferable for investigating several issues.
A large effective sample size is needed to investigate non-linear and time-varying effects in a survival data model.

## References

References Ambler, G.
and Royston, P. (2001) Fractional polynomial model selection procedures: investigation of type I error rate.
J.
Stat.
Comput.
Simul., 69, 89--108.
Becher, H., Lorenz, E., Royston, P., and Sauerbrei, W.
(2012) Analysing covariates with spike at zero: a modiﬁed FP procedure and conceptual issues.
Biom.
J., 54 (5), 686--700.
Binder, H.
and Sauerbrei, W.
(2010) Adding local components to global functions for continuous covariates in multivariable regression modeling.
Stat.
Med., 29, 808--817.
Binder, H., Sauerbrei, W., and Royston, P. (2013) Comparison between splines and fractional polynomials for multivariable model building with continuous covariates: a simulation study with continuous response.
Stat.
Med., 32, 2262--2277.
Breiman, L.
(1992) The little bootstrap and other methods for dimensionality selection in regression: X-ﬁxed prediction error.
J.
Am.
Stat.
Assoc., 87, 78--754.
Buchholz, A.
and Sauerbrei, W.
(2011) Comparison of procedures to assess non-linear and time-varying eﬀects in multivariable models for survival data.
Biom.
J., 53, 308--331.
DOI: 10.1002/bimj.201000159.
Draper, D.
(1995) Assessment and propagation of model selection uncertainty (with discussion).
J.
R. Stat.
Soc.
Ser.
B, 57, 45--97.
Dunkler, D., Sauerbrei, W., and Heinze, G.
(2016) Global, parameterwise and joint post-estimation shrinkage.
J.
Stat.
Softw.
Faes, C., Aerts, M., Geys, H., and Molenberghs, G.
(2007) Model averaging using fractional polynomials to estimate a safe level of exposure.
Risk Anal., 27, 111--123.
Kasenda B., Sauerbrei W., Royston P., Mercat A., Slutsky AS., Cook D., Guyatt GH., Brochard L., Richard JCM., Stewart TE., Meade M., Briel M.
(2016): Multivariable fractional polynomial interaction to investigate continuous effect modifiers in a meta-analysis on higher versus lower PEEP for patients with ARDS.
BMJ Open; 6:e011148, DOI: 10.1136/bmjopen-2016-011148.
Lambert, P.C., Smith, L.K., Jones, D.R., and Botha, J.L.
(2005) Additive and multiplicative covariate regression models for relative survival incorporating fractional polynomials for time-dependent eﬀects.
Stat.
Med., 24, 3871--3885.
Long, J.
and Ryoo, J.
(2010) Using fractional polynomials to model non-linear trends in longitudinal data.
Br.
J. Math.
Stat.
Psychol., 63, 177--203.\

Royston, P. (2014) A smooth covariate rank transformation for use in regression models with a sigmoid dose-response function.
Stata J., 14, 329--341.
Royston, P., Altman, D. G.
(1994).
Regression using fractional polynomials of continuous covariates parsimonious parametric modelling (with discussion).
Applied Statistics 43 (3): 429--467.\

Royston, P. and Sauerbrei, W.
(2004) A new approach to modelling interactions between treatment and continuous covariates in clinical trials by using fractional polynomial.
Stat.
Med., 23, 2509--2525.
Royston, P. and Sauerbrei, W.
(2007) Improving the robustness of fractional polynomial models by preliminary covariate transformation.
Comput.
Stat.
Data Anal., 51, 4240--4253.
Royston, P. and Sauerbrei, W.
(2008) Multivariable Model-Building---A Pragmatic Approach to Regression Analysis Based on Fractional Polynomials for Modelling Continuous Variables, John Wiley & Sons, Chichester, UK. Royston, P. and Sauerbrei, W.
(2013) Interaction of treatment with a continuous variable: simulation study of signiﬁcance level for several methods of analysis.
Stat.
Med., 32 (22), 3788--3803.
Royston, P. and Sauerbrei, W.
(2014) Interaction of treatment with a continuous variable: simulation study of power for several methods of analysis.
Stat.
Med., 33, 4695--4708.
Royston, P., and Sauerbrei, W.
(2016).
mfpa: Extension of mfp using the ACD covariate transformation for enhanced parametric multivariable modeling.
The Stata Journal, 16(1), 72-87.
Royston, P., Sauerbrei, W., and Becher, H.
(2010) Modelling continuous exposures with a 'spike' at zero: a new procedure based on fractional polynomials.
Stat.
Med., 29, 1219--1227.
Sauerbrei, W.
(1999).
The use of resampling methods to simplify regression models in medical statistics.
Appl.
Stat., 48, 313--329.\

Sauerbrei, W., Abrahamowicz, M., Altman, D.G., et al. (2014) STrengthening Analytical Thinking for Observational Strate- gies: the STRATOS initiative.
Stat.
Med., 33 (30), 5413--32.
Sauerbrei W., Buchholz A., Boulesteix A.-L.
and Binder H.
(2015): On stability issues in deriving multivariable regression models.
Biometrical Journal, 57: 531-555, DOI: 10.1002/bimj.201300222.
Sauerbrei, W., Kipruto, E., and Balmford, J.
(2023).
Effects of Influential Points and Sample Size on the Selection and Replicability of Multivariable Fractional Polynomial Models.
Diagnostic and Prognostic Research, to appear Sauerbrei, W., Meier-Hirmer, C., Benner, A., Royston, P. (2006): Multivariable regression model building by using fractional polynomials: description of SAS, STATA and R programs.
Computational Statistics and Data Analysis, 50: 3464-3485 Sauerbrei, W.
and Royston, P. (1999) Building multivariable prognostic and diagnostic models: transformation of the predictors using fractional polynomials.
J.
R. Stat.
Soc.
Ser.
A, 162, 71--94.\

Sauerbrei, W.
and Royston, P. (2011b) A new strategy for meta-analysis of continuous covariates in observational studies.
Stat.
Med., 30 (28), 3341--3360.
Sauerbrei W.
and Royston P. (2011a): Multivariable fractional polynomial models, in: Lovric, M.
(Ed.): International Encyclopedia of Statistical Science, Springer Berlin, p. 899-902.
Sauerbrei, W.
and Royston, P. 2016.
Multivariable Fractional Polynomial Models.
Wiley StatsRef: Statistics Reference Online.
1--8.
DOI: 10.1002/9781118445112.stat07861 Sauerbrei, W.
and Royston, P., 2022.
Investigating treatment-effect modification by a continuous covariate in IPD meta-analysis: an approach using fractional polynomials.
BMC medical research methodology, 22(1), pp.1- Sauerbrei, W., Royston, P., and Binder, H.
(2007b) Selection of important variables and determination of functional form for continuous predictors in multivariable model-building.
Stat.
Med., 26, 5512--5528.
Sauerbrei, W., Royston, P., and Look, M.
(2007a) A new proposal for multivariable modelling of time-varying eﬀects in survival data based on fractional polynomial time-transformation.
Biom.
J., 49, 453--473.\

Shmueli, G.
(2010).
To explain or to predict?
Stat.
Sci., 3, 289--310.
StataCorp.
(2021).
Stata 17 Base Reference Manual.
College Station, TX: Stata Press.
White IR, Kaptoge S, Royston P, Sauerbrei W, Emerging Risk Factors Collaboration (2019): Meta-analysis of non-linear exposure-outcome relationships using individual participant data: A comparison of two methods.
Statistics in Medicine; 38(3): 326-338; doi: 10.1002/sim.7974

