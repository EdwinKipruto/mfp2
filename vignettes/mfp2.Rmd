---
title: "Multivariable Fractional Polynomials with Extensions"
author:
- Edwin Kipruto
- Michael Kammer
- Patrick Royston
- Willi Sauerbrei
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: assets/mfp_refs.bib
link-citations: true
output:
  html_document:
    self_contained: false
    fig_caption: yes
    toc: yes
    toc_depth: 3
    number_sections: yes
    df_print: paged
  word_document:
    fig_caption: yes
    toc: yes
    toc_depth: 3
    number_sections: yes
  pdf_document:
    fig_caption: yes
    toc: yes
    toc_depth: 3
editor_options:
  markdown:
    wrap: sentence
vignette: >
  %\VignetteIndexEntry{Multivariable Fractional Polynomials with Extensions}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
   \usepackage[utf8]{inputenc}
---

```{r include=FALSE}
# the code in this chunk enables us to truncate the print output for each
# chunk using the `out.lines` option
# save the built-in output hook
hook_output <- knitr::knit_hooks$get("output")

# set a new output hook to truncate text output
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x <- xfun::split_lines(x)
    if (length(x) > n) {
        
      # truncate the output
      x <- c(head(x, n), "....\n")
    }
    x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})
```

<!-- justify text in the entire document-->
<style>
body {
  text-align: justify;
}

figcaption {
  text-align: justify;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction to mfp2 package

`mfp2` is a package that selects the MFP model. In addition, it has the ability to model a sigmoid relationship between `x` and an outcome variable `y` using the ACD transformation proposed by Royston (2016). The package offers three options for variable and function selection: p-value, Akaike information criterion (AIC), and Bayesian information criterion (BIC). Furthermore, it provides functions for prediction and plotting. Currently, the package implements linear, logistic, Poisson, and Cox regression models. However, the package is designed in such a way that it can easily incorporate other generalized linear models or parametric survival models.

The main function, `mfp2()`, implements both MFP and MFP with ACD transformation.
It offers two interfaces for input data. The first interface allows direct input of the predictor matrix `x` and the outcome vector `y`. The second interface uses a formula object in conjunction with a data.frame, similar to the `glm()` function
with slight modifications. Both interfaces are equivalent in terms of functionality.


The authors of `mfp2` are Edwin Kipruto, Michael Kammer, Patrick Royston, and Willi Sauerbrei, with contribution from Gregory Steiner and Georg Heinze. The R package is maintained by Edwin Kipruto, while the STATA version of `mfp` is maintained by Patrick Royston. 

This vignette describes basic usage of `mfp2` in R. There are additional vignettes available that will further enhance your understanding on the mfp2 package.

* ["Introduction to Multivariable Fractional Polynomial"](https://github.com/EdwinKipruto/mfp2/tree/main/inst/docs/mfp.html) provides an overview of multivariable fractional polynomials.


## Estimation algorithm
The estimation algorithm employed in `mfp2` sequentially processes the predictors using a back-fitting approach. It calculates the p-values of each predictor 
using the likelihood ratio test, assuming linearity. Subsequently, the 
predictors are arranged based on these p-values. By default, the predictors are arranged in order of decreasing statistical significance. This ordering aims to prioritize modeling relatively important variables before less important ones. 
This approach may help mitigate potential challenges in model fitting arising
from collinearity or more generally, the presence of "concurvity" among the predictors (stata??). Although alternative options for predictor ordering are available, we prefer the default option.

If a predictor contains nonpositive values, the program by default shifts the location of the predictor x to ensure positivity. In addition, it scales the 
shifted predictor before the first cycle of the algorithm. For more information on shifting and scaling, please refer to section xx.

At the initial cycle, the best-fitting FP function for the first variable (after ordering) is determined, with all the other variables assumed to be linear. The functional form (but not the estimated regression
coefficients) is kept, and the process is repeated for the other variables. The
first iteration concludes when all the variables have been processed in this way.
The next cycle is similar, except that the functional forms from the initial cycle are retained for all variables except the one currently being processed


A variable whose functional form is prespecified to be linear is tested
for exclusion within the above procedure when its nominal p-value is less than 1
or argument `keep = FALSE`; otherwise, it is included.
Updating of FP functions and candidate variables continues until the functions
and variables included in the overall model do not change (convergence). 
Convergence is usually achieved within 1â€“5 cycles.


## Installation
To install the `mfp2` package, enter the following command in the R console:
```{r, eval=FALSE}
install.packages("mfp2")
```


## Quick Start
The purpose of this section is to provide users with a comprehensive 
understanding of the `mfp2` package. We will provide a concise overview of its 
key functions and resulting outputs. We will delve into each function in detail, highlighting their specific use. This will provide users with a deeper understanding of the package's functionality. The package includes a built-in dataset that is specifically designed for analysis within the `mfp2` framework. 

To begin, let's load the `mfp2` package:
```{r}
library(mfp2)
```

## Linear Regression
The default `family` in `mfp2` package is `Gaussian`, which fits a Gaussian 
linear model. In this section, we will demonstrate how to fit this model. We will use the prostate cancer data (Stamey et al., 1989) included
in our package. The dataset contains seven predictors (six continuous variables
and one binary variable) and a continuous outcome variable (log prostate-specific antigen (lpsa)) of 97 patients with prostate cancer. Our aim is to determine whether non-linear functional relationships exist between the predictors and
the outcome variable.

Load the `prostate` dataset from the `mfp2` package and display the first few 
rows of the dataset  

```{r out.lines = 10}
data("prostate")
head(prostate)
x <- as.matrix(prostate[,2:8])
y <- as.numeric(prostate$lpsa)
```
The command loads a dataframe from the R data archive since the `mfp2` package 
is already loaded. We create a matrix `x` and a numeric vector `y` from the dataframe. 

### Fitting MFP Models Using Default and Formula Interface

The default interface of `mfp2()` requires a matrix of predictors and a numeric 
vector of response `y` for continuous outcomes. If you have one predictor, make 
sure you convert it into a matrix with a single column.

We fit the Gaussian linear model using the default interface of `mfp2()` with 
default parameters.

```{r, eval=FALSE}
fit <- mfp2(x, y)
```

The fit is an object of class `mfp2` that inherits from `glm` and `lm`. This 
means that `mfp2` inherits properties and methods from `glm` and `lm`, which 
allows the `mfp2` to utilize methods and functions specific to `glm` and `lm`. 
Various methods are defined for extracting components from the `mfp2` object, 
such as coef, print, summary, fracplot, and predict. These methods allow users 
to access different components of the mfp2 object, including coefficient 
estimates, plotting functionalities, and predictions.

We demonstrate how to fit the same model using the formula interface. In this 
case, we will use the `fp()` function. 

```{r, eval=FALSE}
fit <- mfp2(lpsa ~ fp(age) + svi + fp(pgg45) + fp(cavol) + fp(weight) + fp(bph) + fp(cp), data = prostate)
```

The main distinction between the `mfp2()` and `glm()` functions in R is the 
inclusion of the `fp()` function within the formula. The presence of the `fp()` 
function in the formula indicates that the variables included within it should 
undergo fractional polynomial (FP) transformation, provided that the degree of 
freedom (DF) is not equal to 1. A DF of 1 represents a linear relationship,
which does not require transformation. Note that DF is an argument in the 
`fp()` function. For more details on the fp() function, please refer to section
xx

It's important to note that the variable `svi` is a binary variable and is
therefore not passed to the `fp()` function. This is because binary or factor
variables do not undergo FP transformation. However, if a binary variable is 
mistakenly passed to the `fp()` function, the program will automatically set
the DF to 1, treating the variable as linear. However, passing a factor variable
to the `fp()` function will result in an error. For more details on handling 
factor variables, refer to section XX.

### Shifting and Scaling of Predictors
Fractional polynomials are defined only for positive variables due to the use of
logarithms and other powers. Thus, `mfp2()`function estimates shifting factors
for each variables to ensure positivity or assumes that the variables are 
already positive when computing fractional powers of the input variables in case
that shifting is disabled manually. The function `find_shift_factor()` 
automatically estimates shifting factors for continuous variables. 
The formula used to estimate the shifting factor for a variable, say `x1`,
is given by:
\[
\gamma - min(x1)
\]
where $min(x1)$ is the smallest observed value of `x1`, while $\gamma$ is the 
minimum increment between successive ordered sample values of `x1`, excluding 0 
(Royston and Sauerbrei,2008).

For example, to estimate shifting factors for predictor matrix `x` from prostate
data in R, you can run the following code:

```{r}
# minimum values for each predictor
apply(x, 2, min)

# shifting values for each predictor
apply(x, 2, find_shift_factor)
```
We see that among the continuous variables, only the variable `pgg45` is shifted
by a value of 1, which is attributed to its minimum value being 0. Even though
the variable `svi` also has a minimum value of 0, it is not shifted by the 
program because its a binary variable. The user can manually set the shifting 
factors for each variable in `mfp2()` function. 

If the values of the variables are too large or too small, it is important to 
scale the variables to reduce the chances of numerical underflow or overflow 
which can lead to inaccuracies and difficulties in estimating the model. Scaling
can be done automatically or by directly specifying the scaling values for
each variables so that the magnitude of the `x` values are not too extreme. 
By default scaling factors are estimated by the program as follows.

After adjusting the location of `x` so that its minimum value is positive, 
creating `x'` automatic scaling will divide each value of `x'` by 
$10^p$ where the exponent `p` is given by 
\[
p = sign(k) \times floor(|k|) \quad \text{where} \quad k = log_{10} (max(x')- min(x'))
\]

The `mfp2()` function uses this formula to scale `x` matrix, and the scaling 
process is implemented through the `find_scale_factor()` function. The following
R code demonstrates the estimation of scaling factors for `x`. From the output
below, we see that the variables `age`, `cavol`, and `cp` have scaling factors 
of 10 each, while the variables `pgg45` and `weight` have scaling factors of 100
each. Each variable will be divided by its corresponding scaling factor.

```{r}
# shift x 
shift <- apply(x, 2, find_shift_factor)
xnew <- sweep(x, 2, shift, "+")

# scaling factors
apply(xnew, 2, find_scale_factor)

```

To manually enter shifting and scaling factors, the `mfp2()` function provides 
the `shift` and `scale` arguments. In the default usage of `mfp2()`, a vector of
shifting or scaling factors, with a length equal to the number of predictors, can
be provided. In the formula interface, shifting or scaling factors 
can be directly specified within the` fp()` function. Below is an example to 
illustrate this:


```{r, eval = FALSE}
# Default interface
mfp2(x,y, shift = c(0, 0, 1, 0, 0, 0, 0), scale = c(10, 1, 100, 10, 100, 1, 10))

# Formula interface
mfp2(lpsa ~ fp(age, shift = 0, scale = 10) + svi + fp(pgg45, shift = 1, scale = 100) + fp(cavol, shift = 0, scale = 10) + fp(weight, shift = 0, scale = 100) + fp(bph, shift = 0, scale = 1) + fp(cp, shift = 0, scale = 10),
            data = prostate)
```

In the default interface, each variable in the `x` matrix is assigned a shifting 
and scaling factor based on their respective positions. For instance, the first 
variable in the column of `x`, which is `age`, is assigned a shifting factor of 0 
and a scaling factor of 10. The second variable, `svi`, is assigned a shifting 
factor of 0 and a scaling factor of 1, and so on.

### degrees of freedom

```{r out.lines = 10}
fit <- mfp2(x, y)
```

### Gaussian family

## Logistic Regression

## Poisson regression

## Survival data
We illustrate two of the analyses performed by Sauerbrei and Royston (1999). We use
brcancer.dta, which contains prognostic factors data from the German Breast Cancer Study
Group of patients with node-positive breast cancer. The response variable is recurrence-free survival
time (rectime), and the censoring variable is censrec. There are 686 patients with 299 events. We
use Cox regression to predict the log hazard of recurrence from prognostic factors of which five are
continuous (x1, x3, x5, x6, x7) and three are binary (x2, x4a, x4b). Hormonal therapy (hormon) is
known to reduce recurrence rates and is forced into the model. We use mfp to build a model from the
initial set of eight predictors by using the backfitting model-selection algorithm. We set the nominal
p-value for variable and FP selection to 0.05 for all variables except hormon, which it is set to 1:

